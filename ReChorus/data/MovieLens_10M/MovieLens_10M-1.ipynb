{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading interaction data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000054it [00:31, 314202.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5-core filtering...\n",
      "User: 69167/69797, Item: 8790/10258\n",
      "Processing timestamps...\n",
      "Preparing Top-k task data...\n",
      "Processing metadata...\n",
      "Saving processed data...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# 基本配置\n",
    "DATASET = 'ml-10m'\n",
    "RAW_PATH = \"D:/ML/recommendation/ReChorus/data/MovieLens_10M/\"\n",
    "TOPK_PATH = os.path.join(RAW_PATH, 'ML_10MTOPK/')\n",
    "RANDOM_SEED = 0\n",
    "NEG_ITEMS = 99\n",
    "\n",
    "def get_time_range(hour):\n",
    "    \"\"\"获取时间段,与ML-1M保持一致\"\"\"\n",
    "    if hour>=5 and hour<=8:\n",
    "        return 0\n",
    "    if hour>8 and hour<11:\n",
    "        return 1\n",
    "    if hour>=11 and hour<=12:\n",
    "        return 2\n",
    "    if hour>12 and hour<=15:\n",
    "        return 3\n",
    "    if hour>15 and hour<=17:\n",
    "        return 4\n",
    "    if hour>=18 and hour<=19:\n",
    "        return 5\n",
    "    if hour>19 and hour<=21:\n",
    "        return 6\n",
    "    if hour>21:\n",
    "        return 7\n",
    "    return 8 # 0-4 am\n",
    "\n",
    "def download_and_extract():\n",
    "    \"\"\"下载并解压数据集\"\"\"\n",
    "    if not os.path.exists(RAW_PATH):\n",
    "        os.makedirs(RAW_PATH)\n",
    "    if not os.path.exists(os.path.join(RAW_PATH, DATASET + '.zip')):\n",
    "        print('Downloading data into ' + RAW_PATH)\n",
    "        subprocess.call(\n",
    "            'cd {} && curl -O http://files.grouplens.org/datasets/movielens/{}.zip'\n",
    "            .format(RAW_PATH, DATASET), shell=True)\n",
    "        print('Unzip files...')\n",
    "        with zipfile.ZipFile(os.path.join(RAW_PATH, DATASET + '.zip'),'r') as f:\n",
    "            f.extractall(RAW_PATH)\n",
    "\n",
    "def process_data():\n",
    "    \"\"\"处理数据集\"\"\"\n",
    "    print(\"Reading interaction data...\")\n",
    "    interactions = []\n",
    "    user_freq, item_freq = dict(), dict()\n",
    "    \n",
    "    # 1. 读取评分数据\n",
    "    with open(os.path.join(RAW_PATH, \"ml-10M100K/ratings.dat\")) as f:\n",
    "        for line in tqdm(f):\n",
    "            line = line.strip().split(\"::\")\n",
    "            uid, iid, rating, time = line[0], line[1], float(line[2]), float(line[3])\n",
    "            if rating >= 4:  # 与ML-1M保持一致的正样本定义\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            interactions.append([uid, time, iid, label])\n",
    "            if int(label) == 1:\n",
    "                user_freq[uid] = user_freq.get(uid, 0) + 1\n",
    "                item_freq[iid] = item_freq.get(iid, 0) + 1\n",
    "\n",
    "    # 2. 5-core过滤\n",
    "    print(\"Performing 5-core filtering...\")\n",
    "    select_uid, select_iid = [], []\n",
    "    while len(select_uid) < len(user_freq) or len(select_iid) < len(item_freq):\n",
    "        select_uid, select_iid = [], []\n",
    "        for u in user_freq:\n",
    "            if user_freq[u] >= 5:\n",
    "                select_uid.append(u)\n",
    "        for i in item_freq:\n",
    "            if item_freq[i] >= 5:\n",
    "                select_iid.append(i)\n",
    "        print(f\"User: {len(select_uid)}/{len(user_freq)}, Item: {len(select_iid)}/{len(item_freq)}\")\n",
    "\n",
    "        select_uid = set(select_uid)\n",
    "        select_iid = set(select_iid)\n",
    "        user_freq, item_freq = dict(), dict()\n",
    "        interactions_5core = []\n",
    "        for line in interactions:\n",
    "            uid, iid, label = line[0], line[2], line[-1]\n",
    "            if uid in select_uid and iid in select_iid:\n",
    "                interactions_5core.append(line)\n",
    "                if int(label) == 1:\n",
    "                    user_freq[uid] = user_freq.get(uid, 0) + 1\n",
    "                    item_freq[iid] = item_freq.get(iid, 0) + 1\n",
    "        interactions = interactions_5core\n",
    "\n",
    "    # 3. 构建DataFrame并添加时间特征\n",
    "    print(\"Processing timestamps...\")\n",
    "    interaction_df = pd.DataFrame(interactions, columns=[\"user_id\", \"time\", \"news_id\", \"label\"])\n",
    "    interaction_df['timestamp'] = interaction_df['time'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "    interaction_df['hour'] = interaction_df['timestamp'].apply(lambda x: x.hour)\n",
    "    interaction_df['weekday'] = interaction_df['timestamp'].apply(lambda x: x.weekday())\n",
    "    interaction_df['date'] = interaction_df['timestamp'].apply(lambda x: x.date())\n",
    "    interaction_df['period'] = interaction_df.hour.apply(get_time_range)\n",
    "    min_date = interaction_df.date.min()\n",
    "    interaction_df['day'] = (interaction_df.date - min_date).apply(lambda x: x.days)\n",
    "\n",
    "    # 4. 准备Top-k任务数据\n",
    "    print(\"Preparing Top-k task data...\")\n",
    "    os.makedirs(TOPK_PATH, exist_ok=True)\n",
    "    \n",
    "    # 只保留正样本\n",
    "    interaction_pos = interaction_df.loc[interaction_df.label==1].copy()\n",
    "    interaction_pos.rename(columns={\n",
    "        'hour': 'c_hour_c',\n",
    "        'weekday': 'c_weekday_c',\n",
    "        'period': 'c_period_c',\n",
    "        'day': 'c_day_f',\n",
    "        'user_id': 'original_user_id'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # 重新映射ID\n",
    "    user2newid = dict(zip(\n",
    "        sorted(interaction_pos.original_user_id.unique()), \n",
    "        range(1, interaction_pos.original_user_id.nunique()+1)\n",
    "    ))\n",
    "    item2newid = dict(zip(\n",
    "        sorted(interaction_pos.news_id.unique()), \n",
    "        range(1, interaction_pos.news_id.nunique()+1)\n",
    "    ))\n",
    "    \n",
    "    interaction_pos['user_id'] = interaction_pos.original_user_id.apply(lambda x: user2newid[x])\n",
    "    interaction_pos['item_id'] = interaction_pos.news_id.apply(lambda x: item2newid[x])\n",
    "\n",
    "    # 5. 数据集划分\n",
    "    split_time1 = int(interaction_pos.c_day_f.max() * 0.8)\n",
    "    train = interaction_pos.loc[interaction_pos.c_day_f <= split_time1].copy()\n",
    "    val_test = interaction_pos.loc[interaction_pos.c_day_f > split_time1].copy()\n",
    "    val_test.sort_values(by='time', inplace=True)\n",
    "    \n",
    "    split_time2 = int(interaction_pos.c_day_f.max() * 0.9)\n",
    "    val = val_test.loc[val_test.c_day_f <= split_time2].copy()\n",
    "    test = val_test.loc[val_test.c_day_f > split_time2].copy()\n",
    "\n",
    "    # 6. 处理元数据\n",
    "    print(\"Processing metadata...\")\n",
    "    item_meta = pd.read_csv(\n",
    "        os.path.join(RAW_PATH, \"ml-10M100K/movies.dat\"),\n",
    "        sep='::', \n",
    "        names=['movieId', 'title', 'genres'],\n",
    "        encoding='latin-1',\n",
    "        engine='python'\n",
    "    )\n",
    "    \n",
    "    item_select = item_meta.loc[item_meta.movieId.isin(interaction_pos.news_id.unique())].copy()\n",
    "    item_select['item_id'] = item_select.movieId.apply(lambda x: item2newid[x])\n",
    "    \n",
    "    genres2id = dict(zip(\n",
    "        sorted(item_select.genres.unique()),\n",
    "        range(1, item_select.genres.nunique()+1)\n",
    "    ))\n",
    "    item_select['i_genre_c'] = item_select['genres'].apply(lambda x: genres2id[x])\n",
    "    \n",
    "    title2id = dict(zip(\n",
    "        sorted(item_select.title.unique()),\n",
    "        range(1, item_select.title.nunique()+1)\n",
    "    ))\n",
    "    item_select['i_title_c'] = item_select['title'].apply(lambda x: title2id[x])\n",
    "\n",
    "    # 7. 保存数据\n",
    "    print(\"Saving processed data...\")\n",
    "    columns = ['user_id', 'item_id', 'time', 'c_hour_c', 'c_weekday_c', 'c_period_c', 'c_day_f']\n",
    "    \n",
    "    # 保存训练集\n",
    "    train[columns].to_csv(\n",
    "        os.path.join(TOPK_PATH, 'train.csv'),\n",
    "        sep='\\t',\n",
    "        index=False\n",
    "    )\n",
    "    \n",
    "    # 为验证集和测试集生成负样本列\n",
    "    for data, name in [(val, 'dev'), (test, 'test')]:\n",
    "        data['neg_items'] = ''  # 这里可以添加负采样逻辑\n",
    "        data[columns + ['neg_items']].to_csv(\n",
    "            os.path.join(TOPK_PATH, f'{name}.csv'),\n",
    "            sep='\\t',\n",
    "            index=False\n",
    "        )\n",
    "    \n",
    "    # 保存元数据\n",
    "    item_select[['item_id', 'i_genre_c', 'i_title_c']].to_csv(\n",
    "        os.path.join(TOPK_PATH, 'item_meta.csv'),\n",
    "        sep='\\t',\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # download_and_extract()\n",
    "    process_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent4Rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
