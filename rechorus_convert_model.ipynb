{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rechorus_to_agent4rec(rechorus_path, save_path, config_path=None, target_dims=None):\n",
    "    \"\"\"\n",
    "    转换ReChorus模型到Agent4Rec格式\n",
    "    \n",
    "    Args:\n",
    "        rechorus_path: ReChorus模型路径\n",
    "        save_path: 保存转换后的模型路径\n",
    "        config_path: 保存配置文件的路径\n",
    "        target_dims: 目标维度字典 {'user': user_dim, 'item': item_dim}\n",
    "    \"\"\"\n",
    "    # 加载ReChorus模型\n",
    "    rechorus_model = torch.load(rechorus_path)\n",
    "    \n",
    "    if target_dims:\n",
    "        target_user_dim, target_item_dim = target_dims['user'], target_dims['item']\n",
    "    else:\n",
    "        target_user_dim, target_item_dim = 1000, 3292\n",
    "    \n",
    "    # 获取用户和物品embedding的key，需要根据具体模型的key进行调整，需要对应上一步的输出\n",
    "    if 'encoder.embedding_dict' in str(rechorus_model):\n",
    "        model_type = 'LightGCN'\n",
    "        userid = 'encoder.embedding_dict.user_emb'\n",
    "        itemid = 'encoder.embedding_dict.item_emb'\n",
    "    else:\n",
    "        model_type = 'BPRMF'\n",
    "        userid = 'u_embeddings.weight'\n",
    "        itemid = 'i_embeddings.weight'\n",
    "    \n",
    "    # 创建新的state_dict格式\n",
    "    new_state_dict = {\n",
    "        'epoch': 0,\n",
    "        'state_dict': {}\n",
    "    }\n",
    "    \n",
    "    # 转换并调整用户embedding维度\n",
    "    if userid in rechorus_model:\n",
    "        user_weights = rechorus_model[userid]\n",
    "        if user_weights.size(0) > target_user_dim:\n",
    "            new_state_dict['state_dict']['embed_user.weight'] = user_weights[:target_user_dim]\n",
    "        else:\n",
    "            # 如果目标维度更大，需要随机初始化额外的embedding\n",
    "            new_weights = torch.randn(target_user_dim, user_weights.size(1))\n",
    "            new_weights[:user_weights.size(0)] = user_weights\n",
    "            new_state_dict['state_dict']['embed_user.weight'] = new_weights\n",
    "            \n",
    "    # 转换并调整物品embedding维度\n",
    "    if itemid in rechorus_model:\n",
    "        item_weights = rechorus_model[itemid]\n",
    "        if item_weights.size(0) > target_item_dim:\n",
    "            new_state_dict['state_dict']['embed_item.weight'] = item_weights[:target_item_dim]\n",
    "        else:\n",
    "            # 如果目标维度更大，需要随机初始化额外的embedding\n",
    "            new_weights = torch.randn(target_item_dim, item_weights.size(1))\n",
    "            new_weights[:item_weights.size(0)] = item_weights\n",
    "            new_state_dict['state_dict']['embed_item.weight'] = new_weights\n",
    "    \n",
    "    # 保存转换后的模型\n",
    "    torch.save(new_state_dict, save_path)\n",
    "    \n",
    "    # 生成配置文件\n",
    "    if config_path:\n",
    "        config = {\n",
    "            \"vis\": -1,\n",
    "            \"seed\": 0,\n",
    "            \"clear_checkpoints\": True,\n",
    "            \"candidate\": False,\n",
    "            \"test_only\": False,\n",
    "            \"data_path\": \"../datasets/\",\n",
    "            \"dataset\": \"ml-1m\",\n",
    "            \"embed_size\": 64,\n",
    "            \"batch_size\": 256,\n",
    "            \"lr\": 0.001,\n",
    "            \"regs\": 1e-8,\n",
    "            \"epoch\": 200,\n",
    "            \"Ks\": \"5,10,20,50\",\n",
    "            \"verbose\": 5,\n",
    "            \"saveID\": model_type.lower(),\n",
    "            \"patience\": 10,\n",
    "            \"checkpoint\": \"./\",\n",
    "            \"modeltype\": model_type,\n",
    "            \"IPStype\": \"cn\",\n",
    "            \"infonce\": 0,\n",
    "            \"cuda\": 0,\n",
    "            \"n_layers\": 3 if model_type == 'LightGCN' else 0,\n",
    "            \"neg_sample\": 1,\n",
    "            \"num_workers\": 0,\n",
    "            \"train_norm\": False,\n",
    "            \"pred_norm\": False,\n",
    "            \"nodrop\": True\n",
    "        }\n",
    "        \n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump(config, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# lightGCN\n",
    "rechorus_path = \"ReChorus/model/LightGCN/LightGCN__MovieLens_1M/ML_1MTOPK/__0__lr=0.001__l2=1e-08__emb_size=64__n_layers=3__batch_size=256.pt\"\n",
    "config_path = \"Agent4Rec/recommenders/weights/ml-1m/LightGCN/converted_models/args.txt\"\n",
    "target_dims = {'user': 1000, 'item': 3292}\n",
    "\n",
    "log_path = \"ReChorus/log/LightGCN/LightGCN__MovieLens_1M/ML_1MTOPK/__0__lr=0.001__l2=1e-08__emb_size=64__n_layers=3__batch_size=256.txt\"\n",
    "epoch = 0\n",
    "with open(log_path, 'r') as f:\n",
    "    temp = f.read()\n",
    "    pos = temp.find('Best Iter(dev)=')\n",
    "    epoch = int(temp[pos+15:pos+21])\n",
    "    print(epoch)\n",
    "save_path = f\"Agent4Rec/recommenders/weights/ml-1m/LightGCN/converted_models/epoch={epoch}.checkpoint.pth.tar\"\n",
    "\n",
    "convert_rechorus_to_agent4rec(\n",
    "    rechorus_path=rechorus_path,\n",
    "    save_path=save_path,\n",
    "    config_path=config_path,\n",
    "    target_dims=target_dims\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# BPRMF\n",
    "rechorus_path = \"ReChorus/model/BPRMF/BPRMF__MovieLens_1M/ML_1MTOPK/__0__lr=0.001__l2=1e-08__emb_size=64__batch_size=256.pt\"\n",
    "config_path = \"Agent4Rec/recommenders/weights/ml-1m/MF/converted_models/args.txt\"\n",
    "target_dims = {'user': 1000, 'item': 3292}\n",
    "\n",
    "log_path = \"ReChorus/log/BPRMF/BPRMF__MovieLens_1M/ML_1MTOPK/__0__lr=0.001__l2=1e-08__emb_size=64__batch_size=256.txt\"\n",
    "epoch = 0\n",
    "with open(log_path, 'r') as f:\n",
    "    temp = f.read()\n",
    "    pos = temp.find('Best Iter(dev)=')\n",
    "    epoch = int(temp[pos+15:pos+21])\n",
    "    print(epoch)\n",
    "save_path = f\"Agent4Rec/recommenders/weights/ml-1m/MF/converted_models/epoch={epoch}.checkpoint.pth.tar\"\n",
    "\n",
    "convert_rechorus_to_agent4rec(\n",
    "    rechorus_path=rechorus_path,\n",
    "    save_path=save_path,\n",
    "    config_path=config_path,\n",
    "    target_dims=target_dims\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent4Rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
